import pandas as pd
from sentence_transformers import SentenceTransformer
from chromadb import PersistentClient
from chromadb.config import Settings
from chromadb.utils.embedding_functions import EmbeddingFunction
from typing import List, Generator
import os
import torch
from tqdm import tqdm
from processor import process_csv_file

# SentenceTransformer ãƒ¢ãƒ‡ãƒ«
model = SentenceTransformer("intfloat/multilingual-e5-base", device="cuda" if torch.cuda.is_available() else "cpu")

# ChromaDB ç”¨ EmbeddingFunction ã®å®šç¾©
class SentenceTransformerEmbeddingFunction(EmbeddingFunction):
	def __call__(self, input: List[str]) -> List[List[float]]:
		return model.encode(input, convert_to_numpy=True, show_progress_bar=False).tolist()

embedding_function = SentenceTransformerEmbeddingFunction()

# ChromaDB åˆæœŸåŒ–
client = PersistentClient(path="./chroma_db")
collection = client.get_or_create_collection(
	name="rekipedia",
	embedding_function=embedding_function,
)

def show_gpu_info():
	if torch.cuda.is_available():
		print(f"ğŸš€ GPU ä½¿ç”¨ä¸­: {torch.cuda.get_device_name(0)}")
	else:
		print("âš ï¸ GPU ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­ï¼‰")

def send_progress(progress, socketio):
	socketio.emit('progress', {'data': progress})

# ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒƒãƒã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»ChromaDBã¸ç™»éŒ²
def add_chunks_to_chroma_streaming(df: pd.DataFrame, source_id: str, socketio, batch_size=128):
	show_gpu_info()

	resume_file = f".resume_{source_id}.txt"
	processed_count = 0

	if os.path.exists(resume_file):
		with open(resume_file, "r") as f:
			processed_count = int(f.read().strip())
		print(f"ğŸ” {processed_count}ä»¶ç›®ã‹ã‚‰å†é–‹")

	total_chunks = process_csv_file(df)
	total = len(total_chunks)  # ãƒªã‚¹ãƒˆã®é•·ã•ã‚’å–å¾—
	print(f"ğŸ“¦ å‡¦ç†å¯¾è±¡ãƒãƒ£ãƒ³ã‚¯æ•°: {total}")

	with tqdm(total=total - processed_count, desc="ğŸ”„ ç™»éŒ²ä¸­", ncols=80) as pbar:
		for i in range(processed_count, total, batch_size):
			batch = total_chunks[i:i + batch_size]  # ä¿®æ­£
			batch_ids = [f"{source_id}_{j}" for j in range(i, i + len(batch))]
			batch_embeddings = embedding_function(batch)
			collection.add(documents=batch, ids=batch_ids, embeddings=batch_embeddings, metadatas=[{"source": source_id, "row_index": i} for i in range(len(batch))])

			processed_count += len(batch)
			progress = (processed_count / total) * 100
			send_progress(progress, socketio)

			with open(resume_file, "w") as f:
				f.write(str(processed_count))

			pbar.update(len(batch))

	print("âœ… ChromaDBã¸ã®ç™»éŒ²å®Œäº†")
